# 社内AI・RAG機能実装仕様書

**最終更新日**: 2025年8月11日  
**バージョン**: 2.0  
**ステータス**: 実装完了  
**対象システム**: 田中工業GPT（作業記録データベース統合）

---

## 📋 概要

### システム名
**田中工業GPT with RAG** (Retrieval-Augmented Generation)

### 目的
作業記録データベースとAIチャット機能を統合し、社内の製造ノウハウを活用したインテリジェントなAIアシスタントを構築する。

### コンセプト
- **継続的な会話**: チャット形式で自然な対話
- **社内データ活用**: 既存の図番・作業手順・追記データを検索・参照
- **ローカルLLM**: Ollamaによる完全ローカル実行（データセキュリティ確保）
- **高精度検索**: 改良版RAGアルゴリズムによる関連情報の精密検索

---

## 🎯 実装済み機能

### ✅ Phase 1: 基本RAG機能（実装完了）

#### 1.1 高度な検索アルゴリズム（knowledge-search-v2.ts）
- **辞書ベースキーワード抽出**:
  - 材質（20種類以上、エイリアス対応）
  - 機械種別（10種類、類似語対応）
  - 加工プロセス（20種類以上）
  - 工具、難易度、カテゴリ
- **重み付けスコアリング**:
  - 図番完全一致: 10点
  - 機械種別: 4点
  - 材質: 4点
  - 複数項目マッチでブースト（3項目以上で1.5倍）
- **対象データ**:
  - companies.json（会社・製品情報）
  - instruction.json（作業手順メタデータ）
  - contributions.json（追記情報・現場知見）

#### 1.2 ローカルLLM統合（Ollama）
- **4つの実用モデル**:
  - 🧠 賢い - Gemma3 12B（高精度）
  - ⚖️ バランス型 - Qwen2.5 7B
  - ⚡ 軽量・高速 - Gemma3 Q4（量子化版）
  - 💾 省メモリ - Qwen2.5 Q4（デフォルト）
- **完全ローカル実行**: 外部API不要、データ流出なし

#### 1.3 チャットUI
- **吹き出し形式**: 視覚的に分かりやすい対話表示
- **モデル選択**: プルダウンで簡単切り替え
- **RAG機能切り替え**: ON/OFF可能（デフォルトON）
- **レスポンシブ対応**: PC/スマホ両対応

### ✅ Phase 2: 継続的会話機能（部分実装）

#### 2.1 会話コンテキスト管理
- **会話履歴の保持**: セッション中の全会話を記憶
- **コンテキスト制限**: 直近の会話のみ参照（誤検索防止）

#### 2.2 関連データ自動提示
- **検索結果の詳細表示**:
  - マッチした項目の明示
  - 作業ステップ数の表示
  - 使用工具の一覧

### 🚧 Phase 3: 高度なRAG機能（計画中）

#### 3.1 ベクトル検索（設計済み、未実装）
- **Ollamaの埋め込みモデル**: nomic-embed-text
- **コサイン類似度**: 意味的な類似性検索
- **ハイブリッド検索**: キーワード + ベクトル検索

---

## 🏗️ システム構成

### データフロー
```
ユーザー質問
    ↓
田中工業GPT（/chat）
    ↓
キーワード抽出（knowledge-search-v2）
    ↓  
社内データ検索
    ├── companies.json（会社・製品）
    ├── instruction.json（作業手順）
    └── contributions.json（追記）
    ↓
スコアリング・ランキング
    ↓
コンテキスト生成
    ↓
Ollama LLM（ローカル）
    ↓
回答生成（500文字以内）
```

### ファイル構成
```
src/
├── app/
│   ├── api/
│   │   └── chat/
│   │       └── route.ts         # チャットAPI（LLM呼び出し）
│   └── chat/
│       └── page.tsx             # チャットUI
└── lib/
    ├── knowledge-search-v2.ts   # RAG検索アルゴリズム（改良版）
    └── knowledge-search.ts      # 旧版（参考）
```

---

## 💾 検索対象データ構造

### 作業手順メタデータ（instruction.json）
```json
{
  "metadata": {
    "drawingNumber": "0D127100014",
    "title": "ブラケット（チェーンソー）加工手順",
    "machineType": ["マシニング", "ラジアル"],
    "toolsRequired": ["Φ100フルバック", "M4タップ"],
    "difficulty": "上級",
    "estimatedTime": "500分"
  }
}
```

### 会社・製品情報（companies.json）
```json
{
  "id": "chuo-tekko",
  "name": "有限会社中央鉄工所",
  "products": [{
    "name": "チェーンソー",
    "category": "ブラケット",
    "drawings": ["0D127100014"]
  }]
}
```

### 追記情報（contributions.json）
```json
{
  "drawingNumber": "0D127100014",
  "userName": "田中",
  "type": "comment",
  "text": "バランスが悪いため慎重に吊る",
  "timestamp": "2025-08-01T10:00:00Z"
}
```

---

## 🔧 実装詳細

### キーワード抽出関数
```typescript
export function extractKeywords(text: string): ExtractedKeywords {
  // 材質パターン（エイリアス対応）
  const materialPatterns = {
    'sus304': ['sus304', 'ｓｕｓ３０４', 'ステンレス304'],
    'アルミ': ['アルミ', 'アルミニウム', 'al', 'aluminum']
    // ... 20種類以上
  }
  
  // 機械種別パターン（類似語対応）
  const machinePatterns = {
    'マシニング': ['マシニング', 'machining', 'mc', 'マシニングセンタ'],
    '旋盤': ['旋盤', 'turning', 'ターニング', 'lathe']
    // ... 10種類
  }
  
  return {
    materials, machines, processes, tools,
    drawings, companies, difficulties, categories,
    originalQuery
  }
}
```

### スコアリング関数
```typescript
function calculateRelevanceScore(
  keywords: ExtractedKeywords,
  metadata: any,
  matchedFields: string[]
): number {
  const weights = {
    drawingNumber: 10,
    title: 5,
    machineType: 4,
    material: 4,
    tool: 3,
    process: 3
  }
  
  // 複数項目マッチでブースト
  if (matchedFields.length >= 3) score *= 1.5
  
  return score
}
```

---

## 🎬 動作例

### 基本検索
```
ユーザー: 「ブラケットの図面は何件ある？」

【内部処理】
1. キーワード抽出: categories=['ブラケット']
2. データ検索: 19件の図番がマッチ
3. スコアリング: カテゴリマッチで各4点

田中工業GPT: 「ブラケット関連の図面は19件あります。
主な図番：
- 0D127100014: ブラケット（チェーンソー）
- 25417362721: シーサー（R）
- 0A224000531: 穴あけテーブル
...」
```

### 材質・機械指定検索
```
ユーザー: 「SUS304の旋盤加工の注意点は？」

【内部処理】
1. キーワード抽出: materials=['sus304'], machines=['旋盤']
2. RAG検索: 関連図番と追記情報
3. コンテキスト生成

田中工業GPT: 「SUS304の旋盤加工では以下の点にご注意ください：
1. 切削速度は80-120m/minが推奨
2. 切り込みは0.2-0.3mmで開始
3. クーラントは必須（加工硬化防止）
社内事例では送り0.10、切込み0.2が安定しています...」
```

---

## 📊 パフォーマンス特性

### 応答速度
| 処理 | 時間 |
|------|------|
| キーワード抽出 | <50ms |
| RAG検索 | 200-300ms |
| LLM応答（省メモリ版） | 2-3秒 |
| LLM応答（高精度版） | 4-5秒 |

### メモリ要件
- 最小: 8GB RAM（量子化版）
- 推奨: 16GB RAM（フルサイズ版）

---

## 🚀 セットアップ手順

### 1. Ollamaインストール
```bash
# https://ollama.ai/download からダウンロード
```

### 2. モデルダウンロード
```bash
ollama pull qwen2.5:7b-instruct-q4_k_m  # デフォルト
ollama pull gemma3:12b  # オプション
```

### 3. 開発サーバー起動
```bash
npm run dev
# http://localhost:3000/chat でアクセス
```

---

## 🔒 セキュリティ特性

1. **完全ローカル実行**: データが外部に送信されない
2. **アクセス制御**: 管理機能は認証必須
3. **データマスキング**: テスト環境用の匿名化機能

---

## 📈 今後の拡張計画

### 短期（1ヶ月）
- ベクトル検索の実装（nomic-embed-text）
- 検索精度のさらなる向上

### 中期（3ヶ月）
- マルチモーダル対応（画像認識）
- 学習機能（フィードバック活用）

### 長期（6ヶ月）
- 他部門展開
- 外部システム連携

---

## 📚 関連ドキュメント

- [プロジェクト概要仕様書](./プロジェクト概要仕様書_v2.0.md)
- [API仕様書](./API仕様書.md)
- [ベクトル検索実装ガイド](./doc_for_claude/2025-08-11_ベクトル検索実装ガイド.md)
- [AI機能4モデル実装作業メモ](./doc_for_claude/2025-08-11_AI機能4モデル実装作業.md)

---

**作成者**: 開発チーム  
**承認者**: プロジェクトマネージャー  
**次回レビュー**: 2025年9月1日